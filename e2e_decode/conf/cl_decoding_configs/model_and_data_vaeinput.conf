#!/bin/bash

# All the models used for CL
models_base_dir="/export/b15/ssadhu/speech_recognition_tools/e2e"
dataset="wsj"

# TODO : change model1_pm, model_2pm etc with your VAE models
#models_base_dir=".."
model1="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/1/results/model.last10.avg.best"
model1_pm="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model2="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/2/results/model.last10.avg.best"
model2_pm="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"

model3="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/results/model.last10.avg.best"
model3_pm="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model4="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/results/model.last10.avg.best"
model4_pm="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"

model5="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/results/model.last10.avg.best"
model5_pm="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model6="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/results/model.last10.avg.best"
model6_pm="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"

# Dataset used for decoding
dumpdir=${models_base_dir}/${dataset}/dump_fdlp_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1
do_delta=false
train_set="train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1"
recog_set="test_eval92_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1"

# Language model

lmexpname=train_rnnlm_pytorch_lm_word65000
lmexpdir=${models_base_dir}/${dataset}/exp/${lmexpname}

# Result dump
expname=continual_learning_decoding
expdir=exp/${expname}
