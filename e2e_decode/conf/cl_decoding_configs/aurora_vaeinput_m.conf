#!/bin/bash

# All the models used for CL
models_base_dir="/export/b15/ssadhu/speech_recognition_tools/e2e"
dataset="aurora4"
pm_type='vae_old'

# TODO : change model1_pm, model_2pm etc with your VAE models
#models_base_dir=".."
model1="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/1/results/model.last10.avg.best"
model2="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/2/results/model.last10.avg.best"
model3="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/results/model.last10.avg.best"
model4="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/results/model.last10.avg.best"

model1_pm="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model2_pm="${models_base_dir}/wsj/exp/train_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train_no_preprocess_FDLP/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model3_pm="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
model4_pm="${models_base_dir}/reverb/exp/tr_simu_8ch_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"

#model5="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/results/model.last10.avg.best"
#model5_pm="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/1/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"
#model6="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/results/model.last10.avg.best"
#model6_pm="${models_base_dir}/chime4/exp/tr05_multi_noisy_si284_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1_pytorch_train/split2/2/confidence_model/WSJ_px_VAE_enc2l_dec2l_512nodes_bn50/exp_1.dir/exp_1__epoch_100.model"

# Dataset used for decoding
#dumpdir=${models_base_dir}/${dataset}/dump_fdlp_nf80_ord150_fdur1.5_range1100_ola0.25_frate100_DEBUGGED_gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1
#dumpdir=${models_base_dir}/${dataset}/dump_fbank_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1
dumpdir=/export/b15/ssadhu/speech_recognition_tools/e2e/aurora4/dump_fbank_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1
do_delta=false
train_set="train_si284"
recog_set="test_0166_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1"
#et05_real_beamformit_5mics_nf80_ord150_fdur1.5_range1100_ola0.25_frate100__gw_none_cochlear_omw1_alp1_fx_1_bet2.5_wf1
# Language model

lmexpname=train_rnnlm_pytorch_lm_word65000
lmexpdir=${models_base_dir}/${dataset}/exp/${lmexpname}

# Result dump
vae_output_distribution='laplace'
expname=rnn_inp
expdir=../${dataset}/exp/${expname}
